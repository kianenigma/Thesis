\chapter{Background} \label{chap:background}

\begin{chapquote}{David Chum et. al. - 1990}
``The use of credit cards today is an act of faith on the part of all concerned. Each party is
vulnerable to fraud by the others, and the cardholder, in particular, has no protection against
surveillance.''
\end{chapquote}


In this chapter, we dive into the background knowledge needed for the rest of this work. Two primary
pillars of knowledge need to be covered: blockchains and distributed systems in section
\ref{chap_bg:sec:blockchains} and concurrency, upon which our solution will be articulated, in
section \ref{chap_bg:sec:concurrency}.

\section{Blockchains And Distributed Ledger Technology} \label{chap_bg:sec:blockchains}

In this section, we provide an overview of the basics of distributed systems, blockchains, and their
underlying technologies. By the end of this section, it is expected that an average reader will know
enough about blockchain systems to be able to follow the rest of our work, and understand the
approach proposed in chapter \ref{chap:approach} and onwards.

\subsection{Centralized, Decentralized and Distributed Systems} \label{chap_bg_:subsec:network}

An introduction to blockchain is always entangled with \textit{distributed} and
\textit{decentralized} systems.

A distributed system is a system in which a group of nodes (each having their own processor and
memory) cooperate and coordinate for a common outcome. From the perspective of an outside user, most
often the distributed nature of the system is transparent, and all the nodes can be seen and
interacted with, as if they were \textit{one cohesive system}
\cite{bashirMASTERINGBLOCKCHAINDistributed2018}.

Indeed, some details differ between the distributed systems and blockchains, yet the underlying
concepts resonate in many ways \cite{herlihyBlockchainsDistributedComputing2019}, and blockchains
can be seen as a form of distributed systems. Like a distributed system, a blockchain also consists
of many nodes, operated either by organizations, or by normal people with their commodity computers.
Similarly, this \textit{distribution} trait is transparent to the end-user when they want to
interact with the blockchain, and they indeed see the system as one cohesive unit. All of these
nodes together form the \textit{blockchain network}.

\nomenclature{Node}{A single entity in a network.}
\nomenclature{Blockchain Network}{The set of entire nodes holding (a partial) copy of a particular ledger.}

Blockchains are also \textbf{decentralized}. This term was first introduced in a revolutionary paper
in 1964 as a \textbf{middle ground} between purely \textit{centralized} systems that have a single
point of failure, and 100\% \textit{distributed} systems, which are like a mesh (all nodes having
links to many other nodes \cite{baranDistributedCommunicationsNetworks1964} \footnote{The design of
Paul Baran, author of \cite{baranDistributedCommunicationsNetworks1964}, was first proposed, like
many other internet-related technologies, in a military context. His paper was a solution to the
USA's concern about communication links in the aftermath of a nuclear attack in the midst of the
cold war \cite{monicaPaulBaranOrigins}.}). A decentralized system falls somewhere in between, where
no single node's failure can irrecoverably damage the system, and communication is somewhat
distributed, where some nodes might act as hops between different sub-networks.

Blockchains, depending on the implementation, can resonate more with either of the above terms. Most
often, from a networking perspective, they are much closer to the ideals of a distributed system.
From an operational and economical perspective, they can be seen more as decentralized, where the
operational power (i.e. the \textit{authority}) falls into the hands of no single entity, yet a
large enough group of authorities.

\figuremacro
	{figures/networks.png} {Types of Networks.} {From left to right: Centralized, Decentralized, and
	Distributed.}

\subsection{From Ideas to Bitcoin: History of Blockchain} \label{chap_bg_:subsec:hisotry}

While most people associate the rise of blockchains with Bitcoin, it is indeed incorrect, because
the basic ideas of blockchains were mentioned decades earlier. The first relevant research paper was
already mentioned in \ref{chap_bg_:subsec:network}. Namely, in
\cite{baranDistributedCommunicationsNetworks1964}, besides the definition of a decentralized system,
the paper also describes many metrics regarding how secure a network should be, under certain
attacks.

Next, \cite{diffieNewDirectionsCryptography1976} famously introduced what is know as Diffie-Hellman
Key Exchange, which is the backbone of public-key encryption. Moreover, this key exchange is heavily
inspired by \cite{merkleSecureCommunicationsInsecure1978}, which depicts more ways in which
cryptography can be used to secure online communication. Together, these papers form the
\textit{digital signature scheme}, which is heavily used in all blockchain systems \footnote{Many of
these works were deemed military applications at the time, hence the release dates are what is
referred to as the "public dates", not the original, potentially concealed dates of their
discovery.}.

Moreover, the idea of blockchain itself predates Bitcoin. The idea of chaining data together, whilst
placing some digest of the previous piece (i.e. a \textit{hash} thereof) in the header of the next
one was first introduced in \cite{haberHowTimestampDigital1991}. This, in fact, is exactly the
underlying reason that a blockchain, as a data structure, can be seen as an append-only,
tamper-proof ledger. Any change to previous blocks will break the hash chain and cause the hash of
the latest block to become different, making any changes to the history of the data structure
identifiable, hence \textit{tamper-proof}.

Finally, \cite{chaumUntraceableElectronicCash1990} introduced the idea of using digital computers as
a means of currency in 1990, as an alternative to the rise of credit cards at the time. There were a
number of problems with this approach, including the famous double-spend problem, in which an entity
can spend one unit of currency numerous times. Finally, in 2008, an unknown scientist who used the
name Satoshi Nakatomo released the first draft of the Bitcoin whitepaper. In his work, he proposed
Proof of Work as a means of solving the double-spend problem, among other details and improvements
\cite{nakamotoBitcoinPeertoPeerElectronic}. Note that the idea of Proof of Work itself goes back,
yet again, to 1993. This concept was first introduced in
\cite{dworkPricingProcessingCombatting1993}, as means of spam protection in early email services.

\subsection{1000 Feet View of a Blockchain} \label{chap_bg:subsec:100ft}

\figuremacro
	{figures/100ft.png} {A 100ft View of the Blockchain Network} {Nodes (red circles), Ledger state
	(dashed green box), Transaction (green diamonds).}

Before going any further, we provide this, so-called, 1000 feet view of the blockchain. This small
section provides the big picture in the blockchain world, while the upcoming sections go into the
fine depth thereof. This section introduces a lot of jargon all at once, but will help comprehend
the rest of the chapter.

Figure \ref{figure:figures/100ft.png} shows a very broad overview of a blockchain network and the
processes within it. Each red circle is a node in the decentralized network. We zoom into only one
of them. Each node holds two very important components: A runtime, and a ledger (dashed blue box).

The \textbf{ledger} is composed of the chain of blocks, and some auxiliary \textbf{state} for each
block. These two are basically the entire view of the world. The blocks are linked together by a
hash chain. We see a block outside of the state (black block). This is a candidate block, one that
this node might propose to the rest of the network at some point to be appended.

The \textbf{runtime} is simply the core logic of the chain. This core logic, the runtime, has the
responsibility of \textit{updating} the ledger based on \textit{transactions}. Transactions (green
diamonds) are sent to a node from the outer world, potentially from end-users. The transactions are
kept in a separate data structure (transaction queue) until getting a chance at being put into a
block.

\subsection{Preliminary Concepts} \label{chap_bg:sec:preliminary}

Having known where the blockchain's idea originates from, and which fields of previous knowledge in
the last half a century it aggregates, we can now have a closer look at these technologies and
eventually, build up a clear and concrete understanding of what a blockchain is and how it works.

\subsubsection{Elliptic Curve Cryptography} \label{chap_bg:subsec:ecc}

We mentioned the Diffie-Hellman key exchange scheme in section \ref{chap_bg_:subsec:hisotry}. Key
exchange is basically a mechanism to establish a \textit{symmetric} key, using only
\textit{asymmetric} data. In other words, two participants can come up with a common shared
symmetric key (used for encrypting data) without ever sharing it over the network\footnote{Readers
may refer to \cite{diffieNewDirectionsCryptography1976} for more information about the details of
how this mechanism works.}. Indeed, while the underlying principles are the same, for better
performance, most modern distributed systems work with another mechanism that is the more advanced
variant of Diffie-Hellman, namely Elliptic Curve Cryptography (ECC). Elliptic Curves offer the same
properties as Diffie-Hellman, with similar security measures, whilst being faster to compute and
needing smaller key sizes. A key exchange, in short, allows for \textbf{asymmetric cryptography},
the variant of cryptography that needs no secrete medium to exchange initial keys, and therefore is
truly applicable to distributed systems. In asymmetric cryptography, a key \textit{pair} is
generated at each entity. A \textbf{public} key, which can be, as the name suggests, publicly shared
with anyone, and a \textbf{private} key that must be kept secret. Any data signed with the private
key can be verified using the public key. This allows for integrity checks, and allows anyone to
verify the \textit{origin} of a message. Hence, the private key is also referred to as the
\textbf{signature}. Moreover, any data encrypted with the public key can only be decrypted with the
private key. This allows confidentiality.

Many useful properties can be achieved using asymmetric cryptography, and many massively useful
applications adopt it \footnote{The device that you are using to read this line of text has probably
already done at least one operation related to asymmetric cryptography since you started reading
this footnote. This is how relevant they \textit{really} are.}. For blockchains, we are particularly
interested in \textbf{signatures}. Signatures allow entities to verify the integrity and the origin
of any message. Moreover, the public portion of a key, i.e. a public key, can be used as an
identifier for an entity.

For example, in the context of banking, a public key can be seen as an account number. It is public
and known to everyone, and knowing it does not grant anyone the authority to withdraw money from an
account. The private key is the piece that gives one entity \textit{authority} over an account, much
like your physical presence at the bank and signing a paper, in a traditional banking system. This
is a very common pattern in almost all blockchain and distributed systems: using private keys to
sign messages, and using public keys as identities.

RSA and DSA are both non-elliptic signature schemes that are commonly known to date. ECDSA, short
for \textbf{E}lliptic \textbf{C}ureve DSA, is the Elliptic Curve variant of the latter. Albeit,
ECDSA is a subject of debate, due to its proven insecurities \cite{brumleyRemoteTimingAttacks2011},
and its performance. Hence, more recent, non-patented and open standard \footnote{Unlike ECDSA which
is developed and patented by NIST, which in fact is the reason why many people doubt its security.}
curves, such as EdDSA, are the most commonly used. EdDSA, short for Edwards-curve Digital Signature
Algorithm is based on the open standard Edward-curve and its reference, parameters, and
implementation are all public domain.

All in all, cryptography, and specifically digital signatures, play an integral role in the
blockchain technology, and allow it to operate in a distributed way, where external messages can be
verified from their signatures.

\subsubsection{Hash Functions} \label{chap_bg:subsec:hash}

Hash functions, similar to elliptic curve cryptography, are among the mathematical backbones of
blockchains. A hash function is basically a function that takes some bits of data as input and
returns some bits of output in return. All hash functions have an important property: they produce a
\textbf{fixed sized output}, regardless of the input size. Also, a hash function ensures that
changing anything in the input, as small as one bit, does result in an entirely different output.

Given these properties, one can assume that the hash of some piece of data can be seen as its
\textbf{digest}. If the hash of two arbitrarily large pieces of data is the same, you can assume
that their underlying data are indeed the same. This is quite helpful to ensure that some cloned
data is not tampered with, in a distributed environment. If we only distribute the hash of the
original copy in a secure way, everyone can verify that they have a correct clone, without the need
to check anything else.

Albeit, a secure hash function needs to provide more properties. First, the hash function needs to
ensure that no two different inputs can lead to the same hash. This - the situation that different
inputs generate the same hash - is called a \textit{collision}, and the probability of collision in
a hash function should be sufficiently low for it to be secure. Moreover, a hash function must be a
\textit{one way} function, meaning that it cannot be reversed in a feasible manner. By feasible we
effectively mean \textbf{timely}: if reversing a function takes a few million years, it is
\textit{possible}, but not \textit{feasible}. The entire security of hash functions and digital
signatures is based on the fact that breaking them is not feasible \footnote{And, yes, we are aware
of quantum computing, but that is a story for another day.}. So, given some hash output, one cannot
know the input that leads to that hash. Hash functions that have this property are typically called
\textit{cryptographic} hash functions. Cryptographic hash functions are commonly used, next to
asymmetric cryptography, for authentication and integrity checks, where the sender can sign only a
hash of a message and send it over the network, such as in the common \textbf{M}essage
\textbf{A}uthentication \textbf{C}ode, pattern \cite{bellareKeyingHashFunctions1996} (MAC).

\subsubsection{Peer to Peer Network} \label{chap_bg:subsec:p2p}

From a networking perspective, a blockchain is a purely peer to peer distributed network. A peer to
peer network is one in which many nodes form a mesh of connections between them, and they are more
or less of the same role and privilege.

A peer to peer network is the architectural equivalent of what was explained as a
\textbf{distributed} network earlier in this chapter. The opposing architecture is what is known as
the \textit{client-server} model, in which one node is the server and everyone else is a client. In
other words, the client-server model is \textbf{centralized}, in the sense that only the server
contains valuable resources (whatever that resource might be: computation power, data, etc.) and
serves it to all other clients.

Unlike a client-server model, a peer to peer network does not have a single point of failure: there
is no notion of client and server, and all of the entities have the same role, being simply called
\textit{nodes}. Having no servers to serve some data, it is straightforward to say that peer to peer
networks are \textit{collaborative}. A node can consume some resources from another node by
requesting data from it, whilst being the producer for another node by serving data to it. This is
radically different from the traditional client-server model, in which the server is always the
producer and clients are only consumers, and effectively have no control over the data that they are
being served.

Each node in a peer to peer network is constantly talking to other neighboring nodes. For this, they
establish communication links between one another. Regardless of the transport protocol (TCP, QUIC
\cite{carlucciHTTPUDPExperimental2015}, etc.), these connections must be secure and encrypted for
the network to be resilient. Both elliptic curve cryptography and hash functions explained in the
previous sections, provide the technology needed to achieve this.

In the rest of this work, we are particularly interested in the fact that in a blockchain system,
the networking layer provides \textit{gossip} capability. The gossip protocol is an epidemic
procedure to disseminate data to all neighboring nodes, to eventually reach the entire network. In a
nutshell, it is an \textit{eventually consistent} protocol to ensure that some messages are being
constantly gossiped around, until eventually everyone sees them. Blockchains use the gossip protocol
to propagate the messages that they receive from the end-user (the most important of which being
transactions, explained in \ref{chap_bg:subsec:transaction_sig}).

A distributed system must be seen as a cohesive system from outside. Thus, a transaction that a user
submits to one node of the network should have the same chance of being appended to the ledger by
any of the nodes in the future. Therefore, it must be gossiped around. This becomes more clear when
we discuss block authoring in section \ref{chap_bg:subsec:consensus_authorship}.

\subsubsection{Key-Value Database} \label{chap_bg:subsec:kvdb}

Shifting perspective, a blockchain is akin to a distributed database with very high redundancy,
namely one copy per node. One might argue that this is too simplistic, but even the brief
description that we have already provided (see \ref{chap_bg:subsec:100ft}) commensurates with this.
Transactions can be submitted to a blockchain. These transactions are then added to a bundle, called
a block, which is then chained with all the previous blocks, forming a chain of blocks. All nodes
maintain their view of this chain of blocks, and basically, that is what the blockchain is: a
database for storing some chain of blocks.

Now we can explain why in figure \ref{figure:figures/100ft.png} each block was linked with some
auxiliary data. Next to the block database, most blockchains store other data as well, to facilitate
more complex logic. For example, in Bitcoin, that logic needs to maintain a list of accounts and
balances, and perform basic math on top of them\footnote{In reality, Bitcoin does something slightly
different, which is known as the UTXO model, which we omit to explain here for simplicity
\cite{delgado-seguraAnalysisBitcoinUTXO2017}.}. To know an account's balance, it is infeasible to
re-calculate it every time from the known history of previous transactions. That would be equivalent
to an ATM machine re-executing all your previous transactions to know your current balance every
time you use it. Thus, we need some sort of database as well, to store the auxiliary data that the
blockchain logic needs - like, the list of accounts and their balances in our example. This
auxiliary data is called the \textbf{state}, and is usually implemented in the form of a key-value
database.

A key-value database is a database that can be queried similar to a \textit{map}. Any value inserted
in the database needs to be linked with a \textit{key}. This value is then placed in conjunction
with that key. The same key can be used to retrieve, update, or delete the value. For example, in a
bitcoin-like system, the keys are account identifiers (which we already mentioned are most often
just public cryptographic keys), and the values are simply the account balances, some numeric value.

Indeed, a more complicated blockchain, that does more than simple accounting, will have a more
complicated state layout. Even more, chains that support the execution of arbitrary code (e.g. Smart
Contracts \cite{EthereumWhitepaper}), like Ethereum, allow any key-value data pair to be inserted
into the state.

One challenge for nodes in a blockchain network is to keep a \textbf{persistent} view of the state.
For example, Alice's view of how much money Bob owns needs to be the same as everyone else's view.
But, before we dive into this aspect, let us first formalize the means of \textit{updating the
state}: the \textbf{transactions}.

\subsubsection{Transactions and Signatures} \label{chap_bg:subsec:transaction_sig}

\nomenclature{Transaction}{Arbitrary data provided by the outer world that can update the blockchain's state.}
\nomenclature{Origin}{The source (i.e. the sender) of a transaction. Usually Provided through public-key cryptography.}

Transactions are pieces of information submitted to the system, that are eventually appended to the
blockchain in the form of a new block. And, as mentioned, everyone keeps the history of all blocks,
essentially having the ability to replay the history and make sure that an account claiming to have
a certain number of tokens\footnote{Tokens are the equivalent of a monetary unit of currency, like a
coin in the jargon of digital money.} does indeed own it.

The concept of \textit{state} is the main reason why transactions exist. Transactions most often
cause some sort of \textit{update} to happen in the state. Moreover, transactions are accountable,
meaning that they most often contain a signature of their entire payload, to ensure both integrity
and accountability. For example, if Alice wants to issue a \texttt{transfer} transaction to send
some tokens to Bob, the chain will only accept this transaction if is signed with by Alice's private
key. Consequently, if there is a fee associated with this transfer, it is deducted from Alice's
account. This is where the link between identifiers and public keys also becomes more important.
Each transaction has an \textit{origin}, which is basically the identifier of the entity which sent
that transaction. Each transaction also has a signature, which is basically the entire (or only the
sensitive parts of the) payload of the transaction, signed with the private key associated with the
aforementioned origin. Indeed, a transaction is valid only if the signature and the public key
(i.e., the \textit{origin}) match.

This is a radically new usage of public-key cryptography in blockchains, where one can generate a
private key using the computational power of a personal machine, and store some tokens linked to it
on a network operated by many decentralized nodes; that private key is the one and only key that can
unlock those tokens and spend them. Although in this chapter we mostly use examples of a
cryptocurrency (e.g. Bitcoin), we should note that an online currency and token transfer is among
the simplest forms of blockchain transactions. Depending on the functionality of a particular
blockchain, its transactions can have specific logic and complexity. Nonetheless, containing a
\textit{signature} and some notion of \textit{origin} is very common for most use cases.

Let us recap some facts from the previous sections:

\begin{itemize}
	\item A blockchain is a peer to peer network in which a transaction received by one node will
	eventually reach other nodes.
	\item Nodes apply transaction to update some \textit{state}.
	\item Nodes need to keep a persistent view of the state.
\end{itemize}

A system with the combination of the above characteristics can easily come to a race conditions. One
ramification of this race condition is the double-spend problem. Imagine Eve owns 50 tokens. She
sends one transaction to Alice, spending 40 tokens. Alice checks that Eve has enough tokens to make
this spend, updates Eve's account balance to 10, basically updating her own view of the state. Now,
if Eve sends the exact same transaction at the same time to Bob, it will also succeed, if Alice and
Bob have not yet had time to gossip their local transactions to one another.

To solve this, blockchains agree on a contract: the state can \textbf{only} be updated via appending
a new block to the known chain of blocks, not one single transaction at a time. This allows to
compensate for potential gossip delays to some extent, and is explained in more detail in the next
section.

\subsubsection{Blocks} \label{chap_bg:subsec:block}

\nomenclature{Block}{A bundle of transaction that can be appended to the chain.}
\nomenclature{Parent Hash}{A hash of the previous block, mentioned in the header of all blocks.}
\nomenclature{Genesis Block}{The first block of each chain, and it has no parent hash.}

Blocks are nothing but bundles of transactions, and they allow for ordering, which somewhat relaxes
the problem explained in the previous section, namely the race condition between transactions. To do
so, blocks allow nodes to agree on some particular \textit{order} to apply transactions.
Specifically, a node, instead of trying to apply transactions that it has received via the gossip
protocol, in \textit{some random order}, will wait to receive a block from other nodes, and then
apply the transactions therein in the same order as stated in the block. This is called block
\textit{import}.

Transactions inside a block are ordered, and applying them sequentially is fully deterministic: it
will always lead to the same result. Moreover, in the example of the previous section, it is no
longer possible for Eve to spend some tokens twice, because a block will eventually force some
ordering of her transactions, meaning that whichever appears second will indeed fail, because the
effects of the first one are already apparent and persistent in the state of any node that is
executing the block. In other words, as long as a node imports blocks, the transactions within it
are ordered and the aforementioned race condition cannot happen.

A block also contains a small, yet very important piece of data called \textit{parent hash}. This is
basically a hash of the entire content of the last know block of the chain. There is exactly one
block in each chain that has no parent, the first block. This is a special case, and is called the
\textit{genesis block}. This, combined with the properties of the hash function explained in
\ref{chap_bg:subsec:hash}, brings about the tamper-proof-ness of all the blocks. In other words, the
history of operations cannot be mutated. For example, if everyone in the network already knows that
the parent hash of the last known block is $H_1$, it is impossible for Eve to inject, remove, or
change any of the previous transaction, because this will inevitably cause the final hash to be some
other value, $H_2$, which in principle should be very different from $H_1$\footnote{In principle,
the probability of collision (the hash of some \textbf{tampered} chain of blocks being the same as
the valid one) is not absolute zero, but it is so small that it is commonly referred to
\textit{astronomically small}, meaning that it will probably take millions of years for a collision
to happen. As a malicious user, you most often don't want to wait that long.}.

All in all, blocks make the blockchain more tamper-proof (at least the history of transactions), and
bring some ordering constraints regarding the order in which transactions need to be applied.
Nonetheless, with a bit of contemplation, one soon realizes that this is not really solving the race
condition, but rather just changing its \textit{granularity}. Instead of the question of which
transaction to apply next, we now have the problem of which block to append next. This is because,
intentionally, we haven't yet mentioned \textit{who} can propose new blocks to be appended, and
\textit{when}. We have only assumed that we \textit{somehow} receive blocks over the network. This
brings us to the consensus and authorship of blocks, explained in the next section.

\subsubsection{Consensus and Block Authoring} \label{chap_bg:subsec:consensus_authorship}

\nomenclature{Block Authoring}{The sensitive task of preparing a new block and propagating it to the network.}

The consensus protocol in a blockchain consists of a set of algorithms that ensure all nodes in the
network maintain an eventually consistent view of the ledger state (both the chain itself, and the
state). The protocol needs to address problems such as emerging network partition, software
failures, and the Byzantine General Problem \cite{lamportByzantineGeneralsProblem1982}, the sate in
which a portion of the nodes in the network \textit{intentionally} misbehave.

For brevity, we only focus on one aspect of the consensus which is more relevant to our work,
namely, the decision of \textit{block authoring}: deciding who can author blocks, and when.

Recall that nodes in a blockchain network form a distributed system. Therefore, each node could have
a different view of the blockchain, and each node might also have a different set of transactions to
build a new block out of (due to the fact that the underlying gossip might have delivered different
transactions to different nodes at a certain point in time). In principle, any of these nodes can
bundle some transactions in a block and propagate it over the network, \textit{claiming} that it
should be appended to the blockchain. This will indeed lead to chaos. To avoid this, block authoring
is a mechanism to dictate who can author the next block\footnote{In some sense, if blockchains are a
democratic system, block authoring is a protocol to chose a \textit{temporary} dictator.}. This
decision must be solved in a decentralized and provable manner. For example, in Proof of Work, each
block must be hashed together with a variable such that the final of the block hash has a certain
number of leading zeros. This is hard to compute, hence the system is resilient against an invalid
block, namely those that were authored without respecting the authoring rules of the consensus
protocol. Moreover, this is provable: any node that receives a candidate block can hash it again and
ensure that the block is valid with respect to Proof of Work. In this thesis, the terms "block
author" and "validators" are used to refer to the entity that proposes the candidate block, and all
the other nodes that validate it, respectively.

\begin{definition} \label{def:auhtor_validator}

	\textit{Authoring and Validating}.

	\textbf{Author}: the network entity that proposes a new candidate block. This task is called
	block \textit{authoring}.

	\textbf{Validators}: All other nodes who receive this block and ensure its veracity. The act of
	ensuring veracity is called \textit{validating} or \textit{importing} a block.
\end{definition}

In a Proof of Work scheme, the next author is basically whoever manages to solve the Proof of Work
puzzle faster.

\begin{definition} \label{def:pow} Given the adjustable parameter $d$ and a candidate block data
$b$, solving the Proof of Work puzzle is the process of finding a number $n$ such that:

	\begin{equation}
		Hash(b || n) <= d
	\end{equation}

Here, $d$ is usually some power of 2 which is equal to a certain number of leading zeros in the
output.
\end{definition}

Indeed, this is very slow and inefficient, to the point that many have raised concerns even about
the climate impact of the Bitcoin network\footnote{Some estimates show the annual carbon emission of
the Bitcoin network is more than that of Switzerland\cite{stollCarbonFootprintBitcoin2019}.}. There
are other consensus schemes, such as Proof of Stake, combined with verifiable random functions
\cite{dodisVerifiableRandomFunction2005}, that solve the same problem, without wasting a lot of
electricity.

Nonetheless, we can see how this solves the synchronization issue in blockchains. A block serializes
a bundle of transactions. The consensus protocol, namely its block authoring protocol, regulates the
block production, so that not everyone can propose candidate blocks at the same time.

\subsubsection{Interlude: The types of blockchains} \label{chap_bg:subsec:blockchain_types}

So far, we have only talked about \textit{permissionless} blockchains, which are the focus of this
work. Nonetheless, now is a good time to mention that a permissionless blockchain is only one out of
three categories of blockchains:

\begin{itemize}
	\item \textbf{Permissionless} blockchains: A type of blockchain in which no single entity has
	any power over the network. Such networks are called permissionless because one needs no
	permission from any authority to perform an action. For example, as long as one pays the
	corresponding fee, one can always submit a transaction to a permissionless network, i.e. one
	cannot be banned by some authority. Or, one can always decide to be a candidate for block
	authoring, if one wishes to do so. One might not succeed in doing so (e.g. in a Proof of Work,
	weak hardware always fails to find a proper hash in time and essentially waste power with no
	gain), but one has the freedom to do all of these actions. Such blockchains truly adhere to the
	decentralized goals of the blockchain ecosystem.
	\item \textbf{Consortium} blockchains: In this type of blockchains, users can still interact
	with the chain freely, but most \textit{consensus critical} actions are not permissionless. For
	example, a chain might decide to delegate the task of block authoring to a fixed number of
	trusted nodes. In such a scenario, none of the mentioned Proof of Work schemes is needed, and
	the authoring rules can be simplified to a round-robin block authoring. Albeit, such chains are
	questionable because they don't really solve the main problem of making systems trustless. Such
	chains are called Proof of Authority, meaning that a node can author a block by the virtue of
	being a member of a fixed set of authorities \cite{deangelisPBFTVsProofofauthority2018}. And
	from the perspective of the end-user, one must still \textit{trust} in the honesty and goodwill
	of these authorities.
	\item \textbf{Private} blockchains: these blockchains use the same technology as Permissionless
	blockchains to establish trust between organizations, but they are not open to the public. A
	common example would be a chain that maintains government records between different ministries.
\end{itemize}

It is important to note that many aspects of the consensus protocol, including its complexity,
change based on the above taxonomy. The permissionless chains will typically have the most difficult
type of consensus, because ensuring veracity is quite hard in a decentralized environment where
anyone might misbehave. Albeit, the rationale of the decentralization advocates is that by making
the system transparent and open to the public, we actually gain more security comparing to hiding it
behind servers and firewalls\footnote{One reasonably might see this concept resonating with the Open
Source Software movement, where open-source software is claimed to be more secure than a closed
source one.}, because we can also attract more honest participants, who can check the system and
make sure it behaves correctly.

\begin{table}[ht]
\centering
	\caption{Types of blockchain based on consensus.}
	\label{table:blockchain_types}
	\begin{tabular}{lllll}
													& \multicolumn{3}{c}{\textbf{Blockchain Type}} &
													\\
													& Public & Consortium          & Private       &
	\\ \cline{1-4} \multicolumn{1}{l|}{\textbf{Permissionless?}}   & Yes    & No                  &
	No            &  \\
	\multicolumn{1}{l|}{\textbf{Read?}}             & Anyone & Depends             & Invite Only   &
	\\
	\multicolumn{1}{l|}{\textbf{Write?}}            & Anyone & Trusted Authorities & Invite Only   &
	\\
	\multicolumn{1}{l|}{\textbf{Owner}}             & Nobody & Multiple Entities   & Single Entity &
	\\
	\multicolumn{1}{l|}{\textbf{Transaction Speed}} & Slow   & Fast                & Fast          &
	\\ \hline
	\end{tabular}
\end{table}

Due to all this complexity, consensus remains a cutting-edge field of research in the blockchain
ecosystem. In table \ref{table:blockchain_types}, we show how the consensus is also a major factor
in the throughput of the blockchain, which is our metric of interest in this work. This correlation
is later explained in \ref{chap_approach:sec:ways_to_speedup}.

\subsubsection{Forks: A Glitch in The Consensus Protocol}

\nomenclature{Canonical Chain}{The current based chain that most of the nodes agree upon (particularly in the context of a fork).}

Coming back to the \textit{permissionless} block authoring schemes mentioned in
\ref{chap_bg:subsec:consensus_authorship}, it turns out that a perfect consensus cannot exist in a
permissionless network \cite{wangSurveyConsensusMechanisms2019}. Aside from problems such as a node
being malicious and network partitions, there could be other non-malicious scenarios in which
everything in the network is seemingly fine, yet nodes end up with different blockchain views. A
simple scenario that can lead to this is if, by chance, two nodes manage to solve the Proof of Work
puzzle almost at the same time. They both create a \textit{completely valid} block candidate and
propagate it to the network. Some nodes might see one of the candidates first, while the others
might see another one first. Such a scenario is called a \textbf{Fork}: a state in which nodes have
been partitioned into smaller groups, each having their own blockchain views. Most consensus
protocols solve this by adopting a \textit{longest chain} rule. Eventually, once all block
candidates have been propagated, each node chooses the longest chain that they can build, and that
is the accepted one. This chain is called the \textit{canonical chain}, and the last block in it is
called the \textit{best-block} or the \textit{head} of the blockchain. Based on the canonical chain,
the state can also be re-created and stored.

Aside from malicious forks (that we do not cover here), and forks due to decentralization such as
the example above, there could be \textit{federated} forks as well. For example, if a group of nodes
in a blockchain network decide to make a particular change in the history, and they all agree on it,
they can simply fork from the original chain and make their new chain. This new chain has some
common prefix with the original one, but it diverges at some point. A very famous example of this is
the Ethereum Classic fork from Ethereum network \cite{vignaGreatDigitalCurrencyDebate2016}. After a
hack due to a software bug, a lot of funds got frozen in the main Ethereum network. A group of
network participants decided to revert the hack. This was not widely accepted in the Ethereum
ecosystem\footnote{After all, it defies all the \textit{immutability} properties of a blockchain.}
and thus, a fork happened, giving birth to the \textit{Ethereum Classic} network.

\figuremacro{figures/forks.png}{Forks}{The cannon chain and the forked chain both have a common
prefix, yet have \textit{different} best-blocks.}

\subsubsection{Merkle Tree and State Root} \label{chap_bg:subsec:trie}

Recall from \ref{chap_bg:subsec:kvdb} that blockchains store some sort of \textbf{state} next to
their history of blocks as well. We further explain the reasons for this design in this section. To
recap, the state is a key-value database that represents the state of the world, i.e., all the data
that is stored beside the history of blocks. States are mapped with block numbers. With each block,
the transactions within it could potentially alter the state. Hence, we can interpret this term:
"state at block $n$": it means the state, given all the blocks from genesis up to $n$ being
executed.

First, it is important to acknowledge that maintaining the state seems optional, and it is indeed
the case. In principle, a node can decide not to maintain the state, and whenever a state value
needs to be looked up at a block $n$, all the blocks from genesis up to $n$ need to be re-executed.
This is indeed inefficient. On the contrary, maintaining a copy of the state for \textit{all} the
blocks also soon becomes a storage bottleneck. In practice, many chains adopt a middle-ground, in
which normal nodes store only the state associated with the last $k$ blocks.

Without getting into too all the details, we continue with a problem statement: in such a database,
it is very expensive for two nodes to compare their state views with one another. In essence, they
would have to compare \textit{each and every} key-value pair individually. To be able to use this
comparison more efficiently, blockchains use a data structure called a Merkle
tree\footnote{Sometimes referred to as "Trie" as well.} \cite{merkleDigitalSignatureBased1988}. A
Merkle tree\footnote{Named after Ralph Merkle, who also contributed to the foundation of
cryptography in \cite{merkleSecureCommunicationsInsecure1978}.} is a tree in which all leaf nodes
contain some data, and all non-leaf nodes contain the hash of their child nodes.

There are numerous ways to abstract a key-value database with a Merkle tree. For example, one could
hash the keys in the database to get a fixed size, base 16, string. Then, each value will be stored
at a radix-16 tree leaf, which can be traversed by this base 16 hash string.

\figuremacro{figures/trie.png}
	{Merkle Tree} {A binary Merkel Tree. The root hash contains a digest of all the 4 data nodes.}

\nomenclature{State root}{The hash of the entire state, when represented as a Merkle tree.}
In such a data structure, we can clearly see that the root of the Merkle tree has a very important
property: \textit{it is the fingerprint of the \textbf{entire} data}. This piece of data is very
important in blockchains, and is usually referred to as \textbf{state root}. In essence, if two
nodes compute their individual state roots and compare them, this comparison would confidently show
if they have the same state or not. This is very similar to how the existence of the parent hash in
each block ensures that all nodes have the same chain of blocks: changing only a bit in a previous
block, or a state value in this case, will cause the hashes to no longer match. Similarly, changing
only one value in the entire key-value database will cause the state roots to mismatch.

Recalling the definition of author and validator from \ref{def:auhtor_validator}, we can now
elaborate more on what a validator exactly does. A validator node, upon receiving a block, should
check that the block's author is valid (for example check the proof of work puzzle), and then it
re-executes all the transactions in the block, to compute a new state root. Finally, this state root
is compared with the state root that the block author proposed in the block, and if they match, the
block is valid.

We can now summarize all the common data that are usually present in a block's header:

\begin{itemize}
	\item Block number: A numeric representation of the block count, also known as blockchain
	\textit{height}.
	\item Parent hash: This is the signature of the blockchain prefix.
	\item State root: It is common for a block to also name the state root that should be computed,
	if the transactions inside the block body are executed on top of the aforementioned parent hash
	block's state.
\end{itemize}

Our definition of the basic concepts of blockchain almost ends here. In the next sections, we
briefly explain concepts that are more relevant to the implementation of a blockchain, than to the
protocol itself.

\subsubsection{Runtime} \label{chap_bg:subsec:runtime}

\nomenclature{Runtime}{The portion of the blockchain's code that executes transactions.}

We coin the term \textit{Runtime} as the piece of logic in the blockchain that is responsible for
\textit{updating the state}. To be more specific, the runtime of any blockchain can be simplified as
a function that takes a transaction as input, has access to read the state, and (as output)
generates a set of new key-value pairs that need to be updated in the state (or the runtime itself
can update the state directly, depending on the design of the system). This abstraction will be
further used in chapter \ref{chap:approach}.

\begin{definition} Generic Runtime. $runtime = fn(transaction) \rightarrow state$
\end{definition}

\subsubsection{Transaction Queue} \label{chap_bg:subsec:tx_queue}

By defining the transaction queue, we distinguish between transactions that are \textit{included} in
any block, and those that are not. As mentioned, a blockchain node might constantly receive
transactions, either directly from end-users, or from other nodes, as their role in some sort of
gossip protocol. These transactions are all \textit{pending}, and their existence does \textit{not}
imply anything about the state of the blockchain. Only when, by some means of consensus, everyone
agrees to append a block to the chain, the transactions within that block are included in the chain.
Thus, a transaction can be categorized as either \textit{included} and \textit{pending}.

The transaction queue is the place where all the \textit{pending} transactions live in. Its
implementation details are outside the scope of this work, and depend on the needs of the particular
chain. Nonetheless, we highlight the fact that the transaction queue is a component that sits next
to the block authoring process. Once a node wants to author a block (or it just tries to do so, in
cases such as Bitcoin, where some Proof of Work puzzle needs to be solved first), it will use the
transactions that it has received and have been stored in the transaction queue as a source of block
building.

\begin{remark}
	The transaction queue is also sometimes called transaction \textit{pool}. We prefer the term
	queue in this work because later on, we depend on the fact that a queue implies order while a
	pool implies no order.
\end{remark}

\subsubsection{Transaction Validation} \label{chap_bg:subsec:validation}

Usually, a transaction needs to pass some bare minimum checks to even be included in the queue, not
to mention being included in the canonical chain. Usually, checks that are mandatory, persistent,
and rather cheap to compute can happen right when a transaction is being inserted in the queue. For
example, the signature of a transaction must always be valid, and its validity status persists over
time. In other words, if the signature is correct, it will \textit{stay} correct over time. On the
contrary, state-dependent checks usually need to be performed when a transaction is being
\textit{included}, not when it is being inserted into the queue. The reason for this is subtle, yet
very important. If a transaction is asserting to transfer some tokens from Alice to Bob, the
state-dependent check is to make sure Alice has enough tokens. In principle, it is wrong to check
Alice's account balance at the time of inserting the transaction into the queue, since we \textit{do
not know} when this transaction is going to be \textit{included}. What matters is that \textit{at
the block in which this transaction is being included}, Alice must have enough tokens.

That being said, an implementation could optimize the read from the state in some particular way to
allow more checks to happen in the transaction queue layer (one of which is explained in the next
section, \ref{chap_bg:subsec:nonce}). Although, it should be noted that transactions in the queue
are not yet \textit{accountable}, since they are not executed. In other words, a user does not pay
any fees to have their transaction live in the queue. But, they do pay to have their transaction
included in the chain. Therefore, if the queue spends too much time on validation, this can easily
turn into a \textbf{Denial of Service} attack (DoS).

\subsubsection{Account Nonce} \label{chap_bg:subsec:nonce}

\nomenclature{Account Nonce}{An integer linked to each account and incremented per transaction. Used to prevent replay attacks.}
We mentioned that signatures allow transactions to be signed only by an entity that owns a private
key associated with the account. This allows anyone to verify a transaction that claims to spend
some funds from an account. Nonetheless, given that the block history is public, this pattern is
vulnerable to \textit{replay attacks}. A replay attack is an attack in which a malicious user will
submit some (potentially signed) data twice. In the case of a blockchain, Eve can simply look up a
transaction that transfers some money out of Alice's account, and re-submit it back to the chain
numerous times. This is an entirely valid operation by itself, since the transaction that Eve is
submitting again indeed does contain a valid signature from Alice's private key.

To solve this, blockchains that rely on state usually introduce the concept of nonce: a counter that
is associated with each account in state, initially set to zero for every potential account. A
transaction is only valid if, in its signed payload, it provides the nonce value associated with the
origin, incremented by one. Once the transaction is included, the nonce of the account is
incremented by one. This effectively alleviates the vulnerability of replay attacks. Any transaction
that Alice signs, once submitted to the chain and upon being \textit{included}, is no longer valid
for re-submission.

\subsection{Putting it All Together: Decentralized State Transition Logic}
\label{chap_bg:subsec:decentralized_state_machine}

We close our introduction to blockchains by providing a final perspective on their nature. First, we
enumerate some of the lenses through which we have seen blockchains:

\begin{itemize}
	\item A distributed peer to peer network of nodes.
	\item A distributed database of blocks and states.
	\item A decentralized trustless transaction processing unit.
\end{itemize}

We can put all of this together into one frame by representing blockchains as \textbf{state
machines}. This concept resonates well with our notion of state as well. A blockchain is a
\textit{decentralized} state machine. It is a state machine because the state-root hash at the end
of each block is one potential state, and blocks allow for transition between states. Due to forks,
one might have to revert to a previous state. It is decentralized because there is no single entity
that can enforce transition from one state to another one. In fact, any participant can propose
transitions by authoring a block candidate, but it will only ever be considered canon if it is
agreed upon by everyone, through the consensus mechanism. Moreover, each participant stores a copy
of the state. If a single node crashes, goes offline, or decides to misbehave, the integrity of the
system is maintained, as long as there are enough honest participants.


\subsection{Disclaimer: A Note About The Context of Technology}

Before continuing with the chapter, we briefly address the issue of \textit{technology context}. So
far in this chapter, we have used simple examples from the banking world, since it is similar to
Bitcoin, which is a well-known system, and it is easy to explain. Nonetheless, a reader who may have
previously had some background knowledge with some other blockchain project $X$ might soon find some
details that we named here to be less than 100\% compatible with project $X$. Moreover, we have even
admitted throughout the text that some of our examples are not even exactly similar to Bitcoin (such
as the state model, as opposed to the UTXO model).

Such perceived incompatibilities/inaccuracies are predictable to happen, as blockchain systems are a
rapidly evolving field of science and engineering at the moment. Different projects diverge from one
another, even in radical concepts, and experiment with new patterns. Nonetheless, we make the
following assertions about our assumptions in this work:

\begin{itemize}
	\item Whenever we build up a simple example (mostly with Alice and Bob) in this work, we do not
	tie it to any particular blockchain project. Instead, these examples are to be interpreted
	completely independently, and solely based on the relevant concepts explained.
	\item In this entire work, we aim to see blockchains in the most \textit{generic} form that they
	can be seen. That is to say, we interpret blockchains exactly as we defined in
	\ref{chap_bg:subsec:decentralized_state_machine}: a decentralized state machine that can be
	transitioned through means of any form of opaque transaction. An example of this is the
	key-value state model that we used is more generic than the UTXO model\footnote{We have not
	explained UTXO in this work yet, but suffice to say that you can easily implement UTXO with
	key-value but not the other way around.}.
	\end{itemize}

To summarize, we have explained in this section only what we have deemed to be the most fundamental
concepts of blockchains, and we noted whenever a detail could potentially be
implementation-specific. This approach will persist throughout the rest of this work.

\section{Concurrency} \label{chap_bg:sec:concurrency}

In this section, we introduce relevant concepts from the field of concurrency. As mentioned, the
crux of our idea is to deploy concurrency in a blockchain system to gain throughput.

Concurrency is the ability of a software artifact to execute units of its logic (i.e. a
\textit{task}) \textbf{out-of-order}, without causing the outcome to be invalid
\cite{lamportTimeClocksOrdering1978}. If done correctly, this out-of-order execution can be mapped
to different hardware units and improve performance. The opposite viewpoint is a purely in-order
execution, namely sequential.

We link this directly to our example of interest: a node in a blockchain system has a process that
is responsible for executing blocks. By default, this process is purely sequential: all of the
transactions in the block are executed in order, namely the same order as they appear in the block.
Deploying concurrency \textit{should} allow this process to divide the transactions within the block
into a number of smaller groups. Then, these groups can be executed concurrently, without causing an
invalid outcome.

The outcome of interest, of course, is only the aforementioned \textbf{state database} after all of
the transactions of the block are applied. Specifically, as nodes in the network receive blocks and
apply them to a common state, the only acceptable outcome is for all of the nodes to reach the same
state after applying the block\footnote{Note that this is only the case of block validation (block
\textit{import}). There is also the task of block authoring, which is actually more complicated, but
irrelevant to the discussion of this section -- see \ref{def:auhtor_validator}.}. This comparison is
done by means of the state root.

\begin{definition} \label{def:valid_block} \textit{Valid Block}: A block is valid only if its
	execution is deterministic among all of the nodes in the network, and leads to the same state
	root $S^{'}$, if applied on top of a known previous state $S$.
\end{definition}

\begin{remark}
	The deterministic replayability of the transactions is in fact the property that ensures that
	the state is, in principle, optional to keep around, because it is \textit{deterministically
	reproducible} from the chain of blocks.
\end{remark}

Thus, the \textbf{need for determinism is absolute} in a blockchain's runtime environment. This is
in fact why blockchains are designed to work sequentially by default: because it is easy to ensure
determinism when all the transactions are applied sequentially.

Given the execution model of a block, we can reduce the problem to a single node's hardware. Assume
a node is attempting to execute a block, and it has the entire state loaded in memory. If a single
thread executes the transactions within the block, the outcome is deterministic by definition. On
the other hand, if multiple threads try to execute the transactions concurrently and access the
state as they move forward, the result is moot. This is because threads will have to compete over
access to the blockchain state and a typical race condition happens \cite{14:00-17:00ISOIEC9899}.
The challenge is to allow these threads to cooperate and achieve concurrency, while still
maintaining determinism. Therefore, we have translated our blockchain scenario to a typical
shared-state concurrency problem\footnote{We note that the determinism requirement is somewhat
special to our use case and some systems might not require it.}. In such a setup, multiple threads
are competing for access to some shared data (the state), and the runtime environment needs to
resolve the race conditions between the threads.

In the next sections, we present practical ways to use \textit{concurrency over a shared state},
while still generating valid results. Generally, mechanisms that provide more control over the
behavior of concurrent programs are referred to as  \textit{concurrency control}. Among those, we
are essentially looking for those that will allow a valid block to be authored and re-executed, as
defined in \ref{def:valid_block}, most notably deterministically.

\subsection{Locking: Pessimistic Concurrency Control} \label{chap_bg:subsec:lock}

Locks are a common and intuitive mechanism\footnote{Sadly, as we will see, the most intuitive way is
not always the easiest to use.} for concurrency control. A lock is an abstract marker applied to a
shared object (or, generally, to any memory region) to limit the number of threads that can access
it at the same time. The idea of using locks in database systems that want to achieve higher
throughput by using multiple threads goes back many decades ago
\cite{kedemControllingConcurrencyUsing1979, morrisPerformanceAnalysisLocking1985}, among other
fields.

The simplest form of a lock will not distinguish between reads and writes and the only operations on
it are \texttt{acquire} and \texttt{release}. To access the data protected by the lock, first, the
lock itself needs to be acquired. Once a thread acquires a lock, no other threads can: they have to
wait for it. Once the holding thread is done with the lock (more accurately, done with the data
protected by the lock), they release the lock. Upon being released, the lock is acquired by one of
the waiting threads, and the process restarts. This process can easily ensure that some data is
never accessed by multiple threads at the same time. The processor usually ensures that these
primitive operations (\texttt{acquire} and \texttt{release}) are done atomically between threads.
Such locks that do not distinguish between reading and writing are called a \texttt{Mutex}, short
for mutual exclusion \cite{guerraouiLockUnlockThat2019}.

A more elaborate variant of Mutex is a read-write lock (RW-lock). Such locks leverage the fact that
multiple reads from the same data are almost always harmless, and should be allowed - hence the read
and write distinction. In an RW-lock, at any given time, there can be only one writer, but multiple
concurrent readers are allowed.

\begin{remark}
	We use the Rust programming language for the implementation of this work. Rust provides some of
	the finest compile-time memory safety guarantees among all programming languages
	\cite{jungRustBeltSecuringFoundations2017}. To achieve this, Rust references (i.e., addresses to
	memory locations) have the exact same aliasing rule: multiple \textit{immutable} references to a
	data can co-exit in a scope, but \textit{only one} \textit{mutable} reference is allowed
	\cite{weissOxideEssenceRust2020}.
\end{remark}

Locks are easy to understand, but notoriously hard to use \textit{correctly}. A programmer needs to
think about every single critical memory access, and acquire and release locks from different
threads to prevent wrong outcomes. Even worse, immature use of locks often leads the programs to
deadlock, i.e., reach a  state in which all threads are infinitely waiting for a lock acquired (and
never released) by another thread. These issues are common programming errors, but they remain very
hard to detect and resolve \cite{herlihyArtMultiprocessorProgramming2012}.

Moreover, locks are a \textit{pessimistic} mechanism for concurrency control: they assume that if
two threads want to acquire the same (write) lock, their logic \textit{will} cause a conflict to
happen. Based on the granularity of the lock and the internal logic of each thread, a conflict might
not be the case all the time. This is exactly what the next section will address.

\subsection{Transactional Memory: Optimistic Concurrency Control} \label{chap_bg:subsec:stm}

Transactional memory is the opposite of locking when it comes to waiting. In locking, the threads
often need to wait for one another. If a thread is writing, then all the readers and writers need to
wait. This is based on the assumption that mutual acquirement of locks will always lead to
conflicts, so it needs to be prevented in any case. Transactional memory takes the opposite
approach, and assumes that mutual data accesses will \textit{not} conflict by default. In other
words, threads do not need to wait for one another, thus transactional memory is coined "lock-free"
or sometimes "wait-free" \cite{knightArchitectureMostlyFunctional1986}.

In the context of transactional memory, a thread's execution is divided into smaller pieces of logic
called transactions. A transaction attempts to apply one or more updates to some data, without
waiting, and then \textit{commits} the changes. Before a commit, the changes by any transaction are
not visible to any other transaction. Once a commit is about to happen, the runtime must check if
these changes are conflicting or not, based on the previous commits. If committed successfully, the
changes are then visible to all other transactions. Else, none of the changes become visible, the
transaction \textit{aborts}, and the changes are reverted. The great advantage of this model is that
if two transactions access the same memory region, but in a non-conflicting way\footnote{Textbook
example: access two different keys of a concurrent hash map.}, then there is a lot less waiting. In
essence, there is \textit{no} waiting in the execution of transactions, at the cost of some runtime
overhead when they want to commit.

Transactional memory can exist either via specialized hardware or simulated in the software,
referred to as \textit{software} transactional memory, or STM
\cite{hammondTransactionalMemoryCoherence2004}. If implemented in software, transactional memory
does incur a runtime overhead. Nonetheless, its programming interface is much easier and less
error-prone than that of locks, because the programmer does not need to manually acquire and release
locks. \cite{herlihyTransactionalMemoryArchitectural1993}.

Transactional memory is likely to lessen the waiting time and conflicts. Nonetheless, it still
allows threads to operate over the same data structure. This implies complications about commits,
aborts, and coherence\footnote{The question of which changes from a local thread's transaction
become visible to other threads and when, and under which conditions. We have barely touched this
issue, which in itself deserves a thesis to be fully understood.}. A radically different approach is
to try and prevent these complications from the get-go, by disallowing \textit{shared} data to
exist; this mechanism is described in the next section. But first, we briefly note a common trait of
locking and transactional memory.

\subsubsection*{Note About Determinism}

It is very important to note that both locking and transactional memory are non-deterministic. This
means that executing the same workload multiple times may or may not lead to the same output. It is
easy to demonstrate why: first, consider locking. Imagine two threads will soon attempt to compete
for a lock, and each will try and write a different value to a protected memory address. Based on
the fairness rules of the underlying operating system, either of them could be the first one. While
the output of the program in both cases is \textit{correct}, it is \textit{not deterministic}.

The same can be said about transactional memory: if two transactions have both altered the same data
in a conflicting way, one of them is doomed to fail upon trying to commit, and it is just a matter
of which do it first. Again, both outputs are correct, yet the program is not deterministic.

\begin{remark}
	A reader can, at this point, link our use of words "correct" and "determinism" to
	\ref{chap_bg:subsec:consensus_authorship} and block authoring specifically. From the perspective
	of a block author, it does not matter what the outcome of a block is (i.e. which transactions
	are within it, which succeed, and which fail). All such blocks are probably \textit{correct}.
	The first and foremost importance is for all validators to \textit{deterministically} come to
	the same state root, once having received the block later. This is in stark contrast with the
	non-determinism nature of locking.
\end{remark}


\subsection{Sharing vs. Communicating}\label{chap_bg:subsec:sharing_communication}

There is a great quote from the documentation of the Go programming language, which eloquently
explains the point of this section: "Don't communicate by sharing memory; share memory by
communicating." \cite{ShareMemoryCommunicating}. This introduces a radical new approach to
concurrency, in which threads are either stateless or pure functions
\cite{MostlyAdequateMostlyadequateguide}, where their state is private. All synchronization is then
achieved by the means of message passing. Like this, threads do not need to share any common state
or data. If threads need to manipulate the same data, they can send references to the data to one
another. In many cases, this pattern is advantageous compared to locking, both in terms of
concurrency degree and the programming ease.

Nonetheless, we know that our use-case exactly needs some executor threads to have a shared state
while executing the blockchain transactions. Therefore, we do not directly apply the message-passing
paradigm, but we use it as inspiration, and take the possibility of message passing into account. We
revisit this possibility in chapter \ref{chap:approach}.

\subsection{Static Analysis}

As mentioned in \ref{chap_bg:subsec:stm}, transactional memory attempts to reduce the waiting time
by assuming that conflicts are rare. This could bring about two downsides: reverts, in case a
conflict happens, and the general runtime overhead that the system needs to tolerate (for all the
extra machinery needed for transactional memory\footnote{Which is even more if it is being emulated
in the software.}). An interesting approach to counter these limitations is static analysis.
\textit{Static} refers to an action done at compile-time, contrary to runtime. The goal of static
analysis is to somehow improve the concurrency degree by leveraging only compile-time information.
In the case of transactional memory, this could be achieved by using static analysis to predict and
reduce aborts\cite{diasEfficientCorrectTransactional}. Similarly, other studies have tried to use
static analysis to improve the usage of locking by automatically inserting the lock commands into
the program's source code at compile time \cite{cheremInferringLocksAtomic2007}. This can greatly
ease the user experience of programmers using locks, and reduce the chance of human errors to
emerge. Similar to message passing, we take inspiration from the concept of static analysis in our
design later in chapter \ref{chap:approach}.

\section{Recap: Splicing Concurrency and Blockchain}

\ref{chap_bg:sec:blockchains} and \ref{chap_bg:sec:concurrency} cover the background knowledge
needed for the rest of this work. To recap, we formulated blockchains as decentralized state
machines that can be updated by the means of transactions. This state machine maps to a key-value
state database. Attempting to deploy concurrency on blockchains is, therefore, very similar to
shared state concurrency, plus the stark requirement of determinism. Shared state concurrency
attempts to resolve the problem of multiple threads accessing the same underlying memory. We
mentioned both optimistic and pessimistic concurrency, yet have not yet mentioned which one we use.
This is yet to come, in the next chapter.
