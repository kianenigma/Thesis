\chapter{Conclusion} \label{chap:conclusion}

\begin{chapquote}{Edsger Dijkstra}
    Simplicity is a prerequisite for reliability.
\end{chapquote}

We have embarked on a long journey to reach this stage of our work. To make the conclusion more
comprehensible, we first briefly recap what we have done so far, and what we have observed in the
benchmarks of chapter \ref{chap:bench_analysis}. We then enumerate our conclusive observations in
\ref{chap_conc:sec:discussion}. We then answer the research questions in \ref{chap_conc:sec:rq}.
Finally, we mention some of the future work to be done in \ref{chap_conc:sec:future_work}.

\section{Summary}

We began by making minimal, yet important assumptions about what a blockchain system should look
like, whilst explaining the details thereof in chapter \ref{chap:background}. Looking back in
hindsight, the most important assumption that we have is the key-value based \textit{state}
implementation. With the state, we can analogize a runtime executing transaction over a
\textit{state} to a thread in a multi-core CPU, trying to access \textit{memory} as it executes
code. We are then faced with a problem with a setup very similar to that of the shared state
concurrency, except the absolute need for determinism. In essence, determinism is the main
blockchain-specific challenged imposed on this problem.

We identified the de-facto way of solving this challenge in contemporary literature to be building
dependency graphs and piggy-backing them into the block. With further investigation, we decided to
not proceed further down this path: instead, we considered that a much simpler model can be
sufficient, \textit{if} we utilize all of the information available.

In chapter \ref{chap:approach} we declared "\textit{a much simpler model}" to be the
\textit{concurrency delegation} model, where conflicting transactions can be forwarded between
threads when possible, or executed sequentially, at the end of the processing "cycle", otherwise. In
essence, we remove the chance of non-determinism by allowing threads to \textit{only} execute
non-conflicting transactions. In other words: \textit{intra-thread} transactions can conflict as
much as they want, but \textit{inter-thread} transactions must not conflict at all. All transactions
that generate inter-thread conflicts are deemed to be orphan, and will be executed sequentially. The
main advantage of the delegation model is its final outcome: because of the absence of inter-thread
conflicts, the only bit of data that needs to be added to each transaction is one final identifier
about which thread should execute it. The validator is guaranteed to be able to deterministically
re-execute the block, whilst gaining potential throughput benefits.

Furthermore, we make sure we "\textit{utilize all of the information available}" by adding some
pseudo-static hints on top of each transaction. These hints need to be provided by the programmer,
and denote the state keys that are likely to be accessed by the transaction. These hints do not need
to be highly accurate. Moreover, we restricted our hints to data that is cheap to know prior to the
execution of the transaction. Basically, the dilemma is to, not solve, but rather find a way around
the halting problem\cite{burkholderHaltingProblem1987}. To do so, we acknowledge that, most often,
transactions are simple units of logic, with specific behavior given different
inputs\footnote{Blockchain transactions are expensive pieces of code to execute, because they need
to be re-executed by hundreds, if not thousands of other nodes. They are not designed to execute
complex arbitrary logic, and are unlikely to evolve in this direction in the foreseeable future.}.
Given this, it is likely to be easy for the programmer to provide somewhat accurate hints about the
behavior of a transaction.

We combined these features in a concurrent system for high-throughput transaction processing called
SonicChain. Furthermore, we provided a prototype implementation of the system, where we included the
\texttt{access} macro and the \textit{distributors} - see Chapter \ref{chap:impl}. We used this
prototype to evaluate an example application called "the millionaires' playground". We further
benchmarked the performance of this example application. The results, presented in chapter
\ref{chap:bench_analysis}, show throughput improvements for both distributor types, when executed
against a synthetic balance transfer workload.

\section{Discussion and observations} \label{chap_conc:sec:discussion}

Our work has lead to the following observations.

\textbf{The transactions are \textit{key}}. Needless to say, the type of transactions that are being
executed, and the amount of inter-transaction state dependencies between them, is the first and
foremost factor of throughput improvement. This factor trumps the underlying system as well. With a
workload that is made almost entirely from interdependent transactions, even the best of systems
probably fails to deliver high throughput. Moreover, with a workload with almost no
inter-transaction dependencies, probably most systems perform well. We showed, in our experiments,
that our system is no different in that regard. Nonetheless, the important point is that we managed
to achieve ideal throughput gains by effectively leveraging the static hints of the transactions.

\textbf{Simplicity}. Our work is, in some sense, a retaliatory demonstration against complicated
concurrency control mechanisms deployed (mostly in academia) on blockchains. Our main goal was not
to trump their results and prove that our system is better per-se. Rather, we showed that for
certain workloads (that are --reasonably speculating-- not far from reality), a much simpler system
will also be enough. Moreover, the new and simpler system is actually beneficial upon a certain
axis, for example, smaller runtime and block overhead.

\textbf{Generic Design}. This work is generic at two different levels. \textbf{First}, our
\texttt{access} macro is merely one example of how the static\footnote{As before, by static we mean
static with respect to the execution of the transaction.} data that a transaction carries can be
used. Implementations could vary, or different means of analysis can be used. The only point is to
remain aware that the goal is to be able to infer the state access requirements of transactions
\textit{\textbf{without executing them}}. \textbf{Second}, with or without the \textbf{access}
macro, we leave the decision of \textit{how to use the output of static hints} to be generic in the
form of component that we called the distributor. We do provide two such distributors, merely to
illustrate the difference in complexity, and discuss their processing cost, but many other variants
can be envisioned.

\section{Research Questions and Answers} \label{chap_conc:sec:rq}

Based on this work, the answers to our research questions (formulated in section
\ref{chap_intro:sec:resarch_q}) are as follows.

\begin{enumerate}
    \item [\textbf{RQ1}] What approaches exist to achieve concurrent execution of transactions
    within a blockchain system, and improve the throughput?

    \item [\textbf{Answer}] We identified the current usages of concurrency within blockchains to
    within one of the two categories that we depicted: concurrency control or concurrency avoidance.
    Both do result in a throughput gain. Full answer in \ref{chap_approach:existing}.

    \item [\textbf{RQ2}] How could both static analysis and runtime approaches be combined together
    to achieve a new approach with minimum overhead and measurable benefits?

    \item [\textbf{Answer}] We basically opted to reduce the runtime apparatus (coined: concurrency
    delegation) and instead compensate with pseudo-static advisory data that can complement the
    runtime to achieve an equally good result as concurrency control but with less overhead in
    validation. Full answer in \ref{chap_desgin:sec:our_approach}.

    \item [\textbf{RQ3}] How would such an approach be evaluated against and compared to others?

    \item [\textbf{Answer}] We used an empirical evaluation approach to measure the throughput gain.
    A \textit{realistically} synthesized data set was created for this purpose. We concluded that
    our approach is sufficient to achieve ideal throughput gains (given the number of threads) under
    certain circumstances, which supports our claim that a simpler system could be well enough.
\end{enumerate}

Summarizing, this work makes the following contributions:
\begin{enumerate}
    \item A new runtime model for concurrency with minimal overhead, namely concurrency Delegation
    \item A proposal to couple runtime machinery with pseudo-static information for better result.
    \item A first prototype of such a system, namely SonicChain, implemented in the Rust programming
    language.
    \item An empirical analysis of the system against realistic workloads.
\end{enumerate}

\section{Future Work} \label{chap_conc:sec:future_work}

Our discussion and observations already hint at some of the future work that we propose to be
pursued. Here, we enumerate such future work directions in more detail.

\textbf{Inaccurate hints}. We boldly mention that static hints do not need to be accurate for the
system to work properly. Of course, they should not be totally unrelated. A good starting point to
reason about hints is to look at the transaction's logic and proceed with the control flow
optimistically or pessimistically. Which flow has the most state access? Which one has the least?
The interesting follow-up question is how does the behavior of the system change when we move
between different access macros? One might recall, the transfer transaction that we used before had
a pessimistic access macro: we assumed the balance of both the \texttt{origin} and the
\texttt{destination} will be accessed. This is not always the case. If the origin does not have
enough funds, then the transaction finishes with an error, and only the balance key of the origin is
accessed (i.e. \textit{tainted}). We excluded such experiments from our work here for the sake of
brevity.

\textbf{Probabilistic Hints}. An interesting addition to the previous point is the mixing of
probability theorems with the access macro. In essence, instead of relying on the programmer to
provide the hints, the system could use benchmarks and previous data to build probabilistic models
to accurately predict the access requirements of a transaction given specific inputs. This basically
transforms the access macro from being (pseudo)\textit{static} to \textit{probabilistic}. At the
very extreme end of this spectrum, one could even see the utilization of artificial intelligence to
accurately generate the access requirements of a transaction.

\textbf{Read-Write Taint}. A comment on our work that can fundamentally question our approach is:
why is there no distinction between read and write operations? This is a fair comment, and we agree
that it is an unorthodox approach compared to the rest of the literature in concurrent computing. We
did not opt for this approach in our work because of our strong preference for simplicity. There are
many paths to follow along the line of read-write distinction. Most would make our system quite
similar to a cache coherence model, where a write operation needs to be notified to others and
potentially invalidate other previous read operations. This is already a red line for us, as we do
not want to carry the burden of rollbacks, both because of their overhead and inherent
non-determinism. A final interesting comment about this aspect would be that read-write taint is
also likely to introduce read-only \texttt{access} macro hints. We foresee that it will be very
useful for the distributor to be able to know if an access hint is read-only or not. All in all, we
foresee interesting outcomes if the path of read-write taints is pursued, but express worry about
how many complications it will add to the system, compared to the actual throughput gain. The
obvious benefit of this addition to the work would be that threads that only \textit{read} certain
data will not block other threads.

\textbf{Continuous Analysis of Real Chains}. After all, everything that we have done here is in some
sense hypothetical, because we do not use real transaction from a real chain. It is of great value
for further studies to analyze different, domain-specific (e.g. Bitcoin) and general-purpose chains
(e.g. Ethereum), and derive characteristics from their transactions (as it was already done in
\cite{saraphEmpiricalStudySpeculative2019}). For example, an easy study is to apply connected
components to different blocks of the Ethereum network and see how well they can be clustered into
disjoint components with a balanced size. Will we face the same imbalance problem as with our
experiments in chapter \ref{chap:bench_analysis}?

\textbf{Hybrid distributor.} In our work we did not explore the possibility of hybrid distributors.
This can also be a fairly simple addition to the system, making it more versatile. Even only within
the two distributors that we discussed, we could see that it was not the case that one distributor
is the best in all cases. Round robin had limited throughput gains, but it was still better than the
ideal connected components in data sets that had highly intertwined transactions. We propose
building hybrid distributors that potentially chose the best distribution function based on
particular criteria, specific to the application and/or dataset at hand.

\textbf{Nonce-aware execution}. We explained what a nonce is in \ref{chap_bg:subsec:nonce}. A nonce
is of importance to us because it is very likely to be the common key between many transactions that
cause them to become interdependent. For example, imagine an account \texttt{Alice} that has state
keys in different runtime modules. One for balance, and one for different each module. These state
keys can be accessed independently, but bringing the logic of nonce into the picture, things get a
wee bit more complicated. Now, all of these transactions need to write to the key that stores the
nonce of Alice, and they are all dependent on one another. Things can get even worse. There could be
special state keys that need to be accessed by \textit{all} transactions (for example: a counter for
all transaction in the block that is kept in the state). This forcefully makes all of the
transactions in the block sequential if no special treatment is in place for them. And indeed, this
is our main point: we omit such special cases from our work because they should be treated
\textit{specially} in order for any concurrency model to be sensible.
