\chapter{Benchmark and Analysis}  \label{chap:bench_analysis}


\todo[inline]{This would be the answer to question 3.}

\ref{chap_impl:sec:balances} introduced an example runtime module in our implementation, namely a
balances module that can store the balance of different accounts and initiate transfers between
them. In this chapter we will build upon this module and provide benchmarks to evaluate our approach
represented in \ref{chap_desgin:sec:our_approach}. First, we begin by explaining the details of the
benchmarking environment, including the data set.

\section{Benchmarking Environment}

First, we explain the environment details of our measurements. All experiments are executed on a
personal laptop with \texttt{2,3 GHz 8-Core Intel Core i9 CPU} and a \texttt{32 GB 2400 MHz DDR4
RAM} unit. We keep the machine connected to the power for consistent result and run no additional
resource intensive software on the test machine during our measurements.

We measure both \textit{authoring} and \textit{validation} tasks. Recall that authoring is the
process of creating a block and validating is the task of re-importing it to ensure veracity, done
by the \textit{author} and \textit{validator} respectively. Moreover, recall that in our concurrency
delegation model, by the end of authoring phase, all transactions are tagged with the identifier of
the thread that should execute them. Therefore, the validation task is fairly simpler. Furthermore,
we set the \texttt{access} macro of the transfer transaction to point to the account balance key of
the \texttt{origin} and \texttt{destination} account, as demonstrated in
listing \ref{lst:balance_sig}.

\begin{lstlisting}[caption={Signature of the Transfer and its Access Hints}\label{lst:balance_sig}]
#[access = (|origin| vec![
	<BalanceOf<R>>::key_for(origin),
	<BalanceOf<R>>::key_for(dest)
])]
fn transfer(runtime, origin, dest: AccountId, value: Balance) {
}
\end{lstlisting}

Then, we use this information to spawn two benchmarks, one with connected components and one with a
round robin distributor. Indeed, we also use a sequential version as baseline.

The dataset is composed of two parts:

\begin{itemize}
	\item Initial state.
	\item Transactions.
\end{itemize}

The initial state is the state of the world before any transactions are executed. In our case, this
maps to a number of initial accounts and an initial balance in each of them. This is the first
parameter of the dataset.

The second parameter is the number of transactions between the accounts. For example, assuming 100
accounts and 50 transactions, The 50 transactions are generated by picking two random accounts from
the entire set of 100 accounts. These transactions are then placed in a transaction queue, ready for
a runtime to pick them up.

In this chapter we only focus on a variation of this dataset that we call: Millionaire's playground.
This is because we assign a very large amount of initial balance to each account, ensuring that it
is many times larger than they transfer amount. Consequently, all transfers will succeed.

We assume that there are no time limits imposed on the author a block, and allow its runtime to
finish executing all transactions. Of course, as we already delineated ourselves as well, this is
not how things work in reality (see \ref{chap_bg:subsec:consensus_authorship}). Nonetheless, this
model allows us to be able to clearly see the throughput difference between the sequential execution
and the concurrent ones.

From within authoring, we don't measure the execution time of the generic distributor. A critical
reader might think this is a way for us to avoid taking the execution time of connected components
into account. We strongly assert otherwise. In most modern blockchains, authors know, well in
advance, if and when they author blocks. Therefore, it is \textit{only} sensible for them run
the connected components on their pool of transactions in advance, as a form of pre-processing. Even
if they don't know when they will author a block, it is more logical to \textit{continuously} run
the connected components on their local pool iteratively and only make minor corrections when
authoring a block\footnote{Lastly, we anecdotally realized that even running a connected components
is not the a dominant bottleneck in graphs with sizes in the order of a few thousand transactions.}.
For the simpler time of validation, we measure the entire process of parsing the block.

In reality, the state database in likely to be kept on disk, and therefore access to new keys might
be orders of magnitude slower (particularly the first one, depending on the caching) than any
computation. Our implementation keeps the entire state in memory in a \texttt{HashMap}. We
acknowledge that this is likely to be too simplistic and to compensate, we artificially insert
\texttt{sleep} operations into the read and write operations of the final state implementation.

\todo[inline]{did I not mention this before? errr}

Lastly, we assume that all nodes use the same degree of concurrency, meaning that everyone has the
same number of worker threads ready.

\section{Benchmark results} \label{chap_b&a:sec:results}

For the first demonstration, we, fix the number of accounts and gradually create more (transfer)
transactions between them. This is a simple benchmark, yet unravels a great deal of details and
hidden traits about the system's behavior.


\begin{table}[h]
\centering
\caption{Benchmarking Results with Millionaire's Playground Data Set.}
\label{table:bench1}
\resizebox{\textwidth}{!} {
	\begin{tabular}{l|rrrr}
	type                              & \multicolumn{1}{l}{members} & \multicolumn{1}{l}{transactions} & \multicolumn{1}{l}{authoring (ms)} & \multicolumn{1}{l}{validation (ms)} \\ \hline
	Sequential                        & 1000                        & 250                              & 1902                               & 1809                                \\
	Sequential                        & 1000                        & 500                              & 3714                               & 3814                                \\
	Sequential                        & 1000                        & 1000                             & 7642                               & 7641                                \\
	Sequential                        & 1000                        & 2000                             & 15267                              & 15209                               \\ \hline
	Concurrent(RoundRobin-4)          & 1000                        & 250                              & 884                                & 682                                 \\
	Concurrent(RoundRobin-4)          & 1000                        & 500                              & 2249                               & 1872                                \\
	Concurrent(RoundRobin-4)          & 1000                        & 1000                             & 5513                               & 4623                                \\
	Concurrent(RoundRobin-4)          & 1000                        & 2000                             & 12705                              & 10719                               \\ \hline
	Concurrent(ConnectedComponents-4) & 1000                        & 250                              & 633                                & 469                                 \\
	Concurrent(ConnectedComponents-4) & 1000                        & 500                              & 1239                               & 923                                 \\
	Concurrent(ConnectedComponents-4) & 1000                        & 1000                             & 9368                               & 7081                                \\
	Concurrent(ConnectedComponents-4) & 1000                        & 2000                             & 19148                              & 14827
	\end{tabular}
}
\end{table}

Table \ref{table:bench1} demonstrates all the results in one picture. For all the 3 classes of
executions (sequential, round robin, connected components) we generate 1000 members and increase
the number of transactions from 250 to 2000. Both the validation and authoring times are measured.
All executions utilize 4 worker threads.

The important notes of the results are as such:

\begin{itemize}
	\item Sequential: meh. Validation  == authroing.
	\item RR: Somehwat better, gets worse over time and comes closer to sequential: needs logs.
	Reason: forwarding.
	\item CC: Good in tx << member, worse in otherwise: needs logs. Reason linearize.
	\item Validation always less, and shows the degree of effective concurrency that the author
	could came up with. Worse case of CC has a vlidation that is like sequential.
\end{itemize}
